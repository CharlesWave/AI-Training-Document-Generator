{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Stage Training Document Generation\n",
    "\n",
    "This notebook implements a 3-stage process for generating training documents:\n",
    "1. Use Gemini to analyze video and extract knowledge points\n",
    "2. Use Gemini to select timestamps for screenshots (3 separate API calls)\n",
    "3. Use OpenAI GPT-4o to curate screenshots and captions\n",
    "4. Generate final DOCX document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from google import genai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "import re\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Load environment variables with API keys\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize API clients\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "gemni_client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Import prompts\n",
    "from prompts_Three_Stage import stage_1_prompt100, stage_2_prompt100, stage_3_prompt100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Paths and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 1744000241\n",
      "Output folder: training_job_1744000241\n"
     ]
    }
   ],
   "source": [
    "# Configure paths and settings\n",
    "video_path = \"/Users/chaozhang/Downloads/AI KT/KT Recording/modify table in EDW using git.mp4\"\n",
    "job_id = int(time.time())  # Generate a unique ID for this job\n",
    "\n",
    "# Create directories for outputs\n",
    "base_folder = f\"training_job_{job_id}\"\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "# Folders for the 3 API attempts in stage 2\n",
    "screenshots_folders = [\n",
    "    os.path.join(base_folder, f\"screenshots_attempt_{i+1}\") for i in range(3)\n",
    "]\n",
    "for folder in screenshots_folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Final output paths\n",
    "output_json_path = os.path.join(base_folder, \"training_data.json\")\n",
    "output_docx_path = os.path.join(base_folder, \"training_document.docx\")\n",
    "\n",
    "print(f\"Job ID: {job_id}\")\n",
    "print(f\"Output folder: {base_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def extract_screenshots(video_path, timestamps, output_folder, knowledge_point_index, api_attempt_index):\n",
    "    \"\"\"Extract screenshots from video at given timestamps\"\"\"\n",
    "    screenshot_paths = []\n",
    "    \n",
    "    try:\n",
    "        # Open the video file\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Could not open video file {video_path}\")\n",
    "            return []\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps if fps > 0 else 0\n",
    "        \n",
    "        print(f\"Video properties: Duration={duration:.2f}s, FPS={fps:.2f}, Total frames={total_frames}\")\n",
    "        \n",
    "        # Process each timestamp\n",
    "        for screenshot_index, timestamp in enumerate(timestamps):\n",
    "            try:\n",
    "                # Parse timestamp (assuming format like \"1:30\")\n",
    "                if ':' in timestamp:\n",
    "                    minutes, seconds = timestamp.split(':')\n",
    "                    time_in_seconds = int(minutes) * 60 + float(seconds)\n",
    "                else:\n",
    "                    # If only seconds are provided\n",
    "                    time_in_seconds = float(timestamp)\n",
    "                \n",
    "                # Skip if timestamp is beyond video duration\n",
    "                if duration > 0 and time_in_seconds > duration:\n",
    "                    print(f\"Timestamp {timestamp} exceeds video duration of {duration:.2f}s\")\n",
    "                    continue\n",
    "                \n",
    "                # Set the frame position\n",
    "                cap.set(cv2.CAP_PROP_POS_MSEC, time_in_seconds * 1000)\n",
    "                \n",
    "                # Read the frame\n",
    "                success, frame = cap.read()\n",
    "                if success:\n",
    "                    # Generate filename using the specified format\n",
    "                    screenshot_filename = f\"{knowledge_point_index+1}_{screenshot_index+1}_{api_attempt_index+1}.png\"\n",
    "                    screenshot_path = os.path.join(output_folder, screenshot_filename)\n",
    "                    \n",
    "                    # Save the frame\n",
    "                    cv2.imwrite(screenshot_path, frame)\n",
    "                    screenshot_paths.append(screenshot_path)\n",
    "                    print(f\"Saved screenshot: {screenshot_path}\")\n",
    "                else:\n",
    "                    print(f\"Failed to capture screenshot at timestamp {timestamp}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing timestamp {timestamp}: {str(e)}\")\n",
    "        \n",
    "        # Release the video capture\n",
    "        cap.release()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_screenshots: {str(e)}\")\n",
    "    \n",
    "    return screenshot_paths\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \"\"\"Convert an image file to base64 encoded string\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "            return encoded_string\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding image to base64: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def parse_gemini_response(response_text):\n",
    "    \"\"\"Parse the response from Gemini to extract JSON\"\"\"\n",
    "    try:\n",
    "        # Try to parse the entire response as JSON\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # If that fails, look for JSON content in markdown code blocks\n",
    "        json_pattern = r'```(?:json)?\\s*([\\s\\S]*?)\\s*```'\n",
    "        matches = re.findall(json_pattern, response_text)\n",
    "        \n",
    "        if matches:\n",
    "            try:\n",
    "                return json.loads(matches[0])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse JSON from code block: {matches[0]}\")\n",
    "                \n",
    "        # If no code blocks or parsing failed, try to find JSON-like structures\n",
    "        start_idx = response_text.find('{')\n",
    "        end_idx = response_text.rfind('}')\n",
    "        if start_idx >= 0 and end_idx > start_idx:\n",
    "            try:\n",
    "                json_str = response_text[start_idx:end_idx+1]\n",
    "                return json.loads(json_str)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse JSON-like structure: {json_str}\")\n",
    "                \n",
    "        print(\"Could not extract valid JSON from response\")\n",
    "        print(\"Response text:\")\n",
    "        print(response_text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Use Gemini to Extract Knowledge Points from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_service import generate_training_document\n",
    "\n",
    "# Run Stage 1\n",
    "user_prompt = \"Create the training document for this video\"\n",
    "stage1_result_response = generate_training_document(stage_1_prompt100, user_prompt, video_path)\n",
    "\n",
    "try:\n",
    "    stage1_result = json.loads(stage1_result_response)\n",
    "    with open(os.path.join(base_folder, f\"stage1_result.json\"), 'w') as f:\n",
    "        json.dump(stage1_result, f, indent=2)\n",
    "except:\n",
    "    print(\"Failed to parse stage 1 result\")\n",
    "    stage1_result = stage1_result_response\n",
    "    with open(os.path.join(base_folder, f\"stage1_result_raw.txt\"), 'w') as f:\n",
    "        f.write(stage1_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stage1_result['knowledge_points'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Use Gemini to Select Timestamps (3 Attempts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stage 2: Selecting Timestamps for Screenshots ===\n",
      "\n",
      "Attempt 1/3: Calling Gemini API for timestamp selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Response is not valid JSON after cleaning: Extra data: line 6 column 4 (char 49)\n",
      "Invalid JSON response (first 500 chars): {\n",
      "    \"0\": [\n",
      "      \"0:16\",\n",
      "      \"0:21\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"1\": [\n",
      "      \"0:24\",\n",
      "      \"0:42\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"2\": [\n",
      "      \"0:58\",\n",
      "      \"1:02\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"3\": [\n",
      "      \"1:06\",\n",
      "      \"1:17\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"4\": [\n",
      "      \"1:33\",\n",
      "      \"1:55\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"5\": [\n",
      "      \"2:01\",\n",
      "      \"2:23\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"6\": [\n",
      "      \"2:33\",\n",
      "      \"2:39\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"7\": [\n",
      "      \"2:40\",\n",
      "      \"2:44\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"8\": [\n",
      "      \"2:44\",\n",
      "      \"2:47\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"9\": [\n",
      "      \"3:0\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 6 column 4 (char 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 100\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m stage2_result\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Run Stage 2\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m stage2_result = \u001b[43mstage2_select_timestamps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage1_result\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mstage2_select_timestamps\u001b[39m\u001b[34m(video_path, stage1_result)\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(raw_response_path, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     35\u001b[39m     f.write(response_text)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m timestamps_data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m timestamps_data \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(timestamps_data, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: Failed to parse response from Gemini\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:347\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    345\u001b[39m end = _w(s, end).end()\n\u001b[32m    346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 6 column 4 (char 49)"
     ]
    }
   ],
   "source": [
    "# Stage 2: Use Gemini to select timestamps for knowledge points\n",
    "from ai_service import generate_training_document\n",
    "\n",
    "def stage2_select_timestamps(video_path, stage1_result):\n",
    "    print(\"=== Stage 2: Selecting Timestamps for Screenshots ===\")\n",
    "    \n",
    "    # Check if we have the required data from Stage 1\n",
    "    if not stage1_result or 'knowledge_points' not in stage1_result:\n",
    "        print(\"Error: Missing required data from Stage 1\")\n",
    "        return None\n",
    "\n",
    "    # Create prompt with video and knowledge points\n",
    "    knowledge_points = stage1_result['knowledge_points']\n",
    "    \n",
    "    # Replace placeholder in prompt template\n",
    "    prompt = stage_2_prompt100.replace(\"{{summary_from_stage_1}}\", json.dumps(stage1_result.get('summary', '')))\n",
    "      \n",
    "    # Run 3 separate API calls and collect timestamps\n",
    "    all_attempt_results = []\n",
    "    all_screenshot_paths = []\n",
    "    \n",
    "    for attempt in range(3):\n",
    "        print(f\"\\nAttempt {attempt+1}/3: Calling Gemini API for timestamp selection...\")\n",
    "        \n",
    "        # Call the Gemini API\n",
    "        user_prompt = f'''\n",
    "        Provide timestamps of screenshots for demonstrating each knowledge point in below list \n",
    "        {knowledge_points}\n",
    "        '''\n",
    "        response_text = generate_training_document(prompt, user_prompt, video_path)\n",
    "        \n",
    "        # Save the raw response\n",
    "        raw_response_path = os.path.join(base_folder, f\"stage2_raw_response_attempt_{attempt+1}.txt\")\n",
    "        with open(raw_response_path, 'w') as f:\n",
    "            f.write(response_text)\n",
    "        \n",
    "        timestamps_data = json.loads(response_text)\n",
    "        \n",
    "        if not timestamps_data or not isinstance(timestamps_data, list):\n",
    "            print(f\"Attempt {attempt+1}: Failed to parse response from Gemini\")\n",
    "            continue\n",
    "        \n",
    "        # Save parsed response\n",
    "        parsed_response_path = os.path.join(base_folder, f\"stage2_parsed_response_attempt_{attempt+1}.json\")\n",
    "        with open(parsed_response_path, 'w') as f:\n",
    "            json.dump(timestamps_data, f, indent=2)\n",
    "        \n",
    "        print(f\"Attempt {attempt+1}: Successfully parsed response\")\n",
    "        \n",
    "        # Extract timestamps for each knowledge point\n",
    "        attempt_screenshots = []\n",
    "        \n",
    "        # Extract screenshots based on timestamps\n",
    "        for knowlege_point in timestamps_data:\n",
    "            for knowledge_point_index, timestamps in knowlege_point.items():\n",
    "                try:\n",
    "                    # Convert string index to integer if needed\n",
    "                    if isinstance(knowledge_point_index, str) and knowledge_point_index.isdigit():\n",
    "                        knowledge_point_index = int(knowledge_point_index)\n",
    "                    \n",
    "                        # Extract screenshots\n",
    "                        print(f\"Extracting screenshots for knowledge point {knowledge_point_index+1}\")\n",
    "                        screenshot_paths = extract_screenshots(\n",
    "                            video_path, timestamps, screenshots_folders[attempt],\n",
    "                            knowledge_point_index, attempt\n",
    "                        )\n",
    "                        \n",
    "                        attempt_screenshots.append({\n",
    "                            \"knowledge_point_index\": knowledge_point_index,\n",
    "                            \"timestamps\": timestamps,\n",
    "                            \"screenshot_paths\": screenshot_paths\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing knowledge point {knowledge_point_index}: {str(e)}\")\n",
    "        \n",
    "        all_attempt_results.append(attempt_screenshots)\n",
    "        \n",
    "        # Collect all screenshot paths\n",
    "        all_paths = []\n",
    "        for item in attempt_screenshots:\n",
    "            all_paths.extend(item[\"screenshot_paths\"])\n",
    "        all_screenshot_paths.extend(all_paths)\n",
    "        \n",
    "        print(f\"Attempt {attempt+1}: Extracted {len(all_paths)} screenshots\")\n",
    "    \n",
    "    # Save combined results\n",
    "    stage2_result = {\n",
    "        \"attempt_results\": all_attempt_results,\n",
    "        \"all_screenshot_paths\": all_screenshot_paths\n",
    "    }\n",
    "    \n",
    "    stage2_result_path = os.path.join(base_folder, \"stage2_result.json\")\n",
    "    with open(stage2_result_path, 'w') as f:\n",
    "        json.dump(stage2_result, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nStage 2 completed with {len(all_screenshot_paths)} total screenshots across 3 attempts\")\n",
    "    return stage2_result\n",
    "\n",
    "# Run Stage 2\n",
    "stage2_result = stage2_select_timestamps(video_path, stage1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Use o1 to Curate Screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_1_1\n",
      "1_2_1\n",
      "1_1_2\n",
      "1_2_2\n",
      "1_1_3\n",
      "1_2_3\n",
      "2_1_1\n",
      "2_2_1\n",
      "2_1_2\n",
      "2_2_2\n",
      "2_1_3\n",
      "2_2_3\n",
      "3_1_1\n",
      "3_2_1\n",
      "3_1_2\n",
      "3_2_2\n",
      "3_1_3\n",
      "3_2_3\n",
      "4_1_1\n",
      "4_2_1\n",
      "4_1_2\n",
      "4_2_2\n",
      "4_1_3\n",
      "4_2_3\n",
      "5_1_1\n",
      "5_2_1\n",
      "5_1_2\n",
      "5_2_2\n",
      "5_1_3\n",
      "5_2_3\n",
      "6_1_1\n",
      "6_2_1\n",
      "6_1_2\n",
      "6_2_2\n",
      "6_1_3\n",
      "6_2_3\n",
      "7_1_1\n",
      "7_2_1\n",
      "7_1_2\n",
      "7_2_2\n",
      "7_1_3\n",
      "7_2_3\n",
      "8_1_1\n",
      "8_2_1\n",
      "8_1_2\n",
      "8_2_2\n",
      "8_1_3\n",
      "8_2_3\n",
      "9_1_1\n",
      "9_2_1\n",
      "9_1_2\n",
      "9_2_2\n",
      "9_1_3\n",
      "9_2_3\n",
      "10_1_1\n",
      "10_2_1\n",
      "10_1_2\n",
      "10_2_2\n",
      "10_1_3\n",
      "10_2_3\n",
      "11_1_1\n",
      "11_2_1\n",
      "11_1_2\n",
      "11_2_2\n",
      "11_1_3\n",
      "11_2_3\n",
      "12_1_1\n",
      "12_2_1\n",
      "12_1_2\n",
      "12_2_2\n",
      "12_1_3\n",
      "12_2_3\n",
      "13_1_1\n",
      "13_2_1\n",
      "13_1_2\n",
      "13_2_2\n",
      "14_1_1\n",
      "14_2_1\n",
      "14_1_2\n",
      "14_2_2\n",
      "15_1_1\n",
      "15_2_1\n",
      "15_1_2\n",
      "15_2_2\n",
      "16_1_1\n",
      "16_2_1\n",
      "16_1_2\n",
      "16_2_2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_points = stage1_result_json['knowledge_points']\n",
    "curated_results = []\n",
    "\n",
    "\n",
    "# Process each knowledge point\n",
    "for knowledge_point_index, knowledge_point in enumerate(knowledge_points):\n",
    "    \n",
    "    # Collect all screenshots for this knowledge point from all attempts\n",
    "    point_screenshots = []\n",
    "    point_screenshot_ids = []\n",
    "    \n",
    "    for attempt_index, attempt_result in enumerate(stage2_result['attempt_results']):\n",
    "        for item in attempt_result:\n",
    "            if item[\"knowledge_point_index\"] == knowledge_point_index:\n",
    "                for screenshot_index, path in enumerate(item.get(\"screenshot_paths\", [])):\n",
    "                    # Extract base filename as ID\n",
    "                    filename = os.path.basename(path)\n",
    "                    name_without_ext = os.path.splitext(filename)[0]\n",
    "                    print(name_without_ext)\n",
    "                    \n",
    "                    point_screenshots.append(path)\n",
    "                    point_screenshot_ids.append(name_without_ext)\n",
    "\n",
    "point_screenshot_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stage 3: Curating Screenshots with o1 ===\n",
      "\n",
      "Processing knowledge point 1/25\n",
      "Open Visual Studio Code.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 2/25\n",
      "Open the Git repository folder in Visual Studio Code.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 3/25\n",
      "Switch to the develop branch.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 4/25\n",
      "Pull the latest version of the develop branch to get the latest changes.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 1 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 5/25\n",
      "Create a new branch from the develop branch for making changes.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 6/25\n",
      "The branch name should be the Jira ticket number.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 7/25\n",
      "Locate the code that needs to be modified.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 8/25\n",
      "Modify the code as needed.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 9/25\n",
      "Save the changes.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 10/25\n",
      "Go to the EDW dev folder.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 1 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 11/25\n",
      "Open the edw_dev_deploy_files.txt file.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 12/25\n",
      "Input the path of the code that was modified in the deploy file.\n",
      "Found 6 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 6 screenshots\n",
      "\n",
      "Processing knowledge point 13/25\n",
      "Go to the edw_dev_version.txt file.\n",
      "Found 4 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 4 screenshots\n",
      "\n",
      "Processing knowledge point 14/25\n",
      "Increment the version number by one in the edw_dev_version.txt file.\n",
      "Found 4 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 4 screenshots\n",
      "\n",
      "Processing knowledge point 15/25\n",
      "Save the changes.\n",
      "Found 4 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 4 screenshots\n",
      "\n",
      "Processing knowledge point 16/25\n",
      "Go to Source Control.\n",
      "Found 4 screenshots for curation\n",
      "Calling o1 API for curation...\n",
      "GPT-4o selected 2 out of 4 screenshots\n",
      "\n",
      "Processing knowledge point 17/25\n",
      "Stage the changes.\n",
      "No screenshots found for knowledge point 17\n",
      "\n",
      "Processing knowledge point 18/25\n",
      "Commit the changes with a descriptive message.\n",
      "No screenshots found for knowledge point 18\n",
      "\n",
      "Processing knowledge point 19/25\n",
      "Push the changes.\n",
      "No screenshots found for knowledge point 19\n",
      "\n",
      "Processing knowledge point 20/25\n",
      "Create a pull request.\n",
      "No screenshots found for knowledge point 20\n",
      "\n",
      "Processing knowledge point 21/25\n",
      "Set auto-complete for the pull request.\n",
      "No screenshots found for knowledge point 21\n",
      "\n",
      "Processing knowledge point 22/25\n",
      "Copy the pull request URL.\n",
      "No screenshots found for knowledge point 22\n",
      "\n",
      "Processing knowledge point 23/25\n",
      "Share the pull request URL in the team chat.\n",
      "No screenshots found for knowledge point 23\n",
      "\n",
      "Processing knowledge point 24/25\n",
      "After the pull request is approved, go to Pipelines.\n",
      "No screenshots found for knowledge point 24\n",
      "\n",
      "Processing knowledge point 25/25\n",
      "Run the Unifier EDW Dev Snowflake pipeline to execute the script.\n",
      "No screenshots found for knowledge point 25\n",
      "\n",
      "Stage 3 completed with 30 selected screenshots across 25 knowledge points\n"
     ]
    }
   ],
   "source": [
    "# Stage 3: Use GPT-4o to curate screenshots\n",
    "\n",
    "def stage3_curate_screenshots(stage1_result, stage2_result):\n",
    "    print(\"=== Stage 3: Curating Screenshots with o1 ===\")\n",
    "    \n",
    "    # Check if we have the required data from Stages 1 and 2\n",
    "    if not stage1_result or 'knowledge_points' not in stage1_result:\n",
    "        print(\"Error: Missing required data from Stage 1\")\n",
    "        return None\n",
    "    \n",
    "    if not stage2_result or 'attempt_results' not in stage2_result:\n",
    "        print(\"Error: Missing required data from Stage 2\")\n",
    "        return None\n",
    "    \n",
    "    # Organize screenshots by knowledge point\n",
    "    knowledge_points = stage1_result['knowledge_points']\n",
    "    curated_results = []\n",
    "    \n",
    "    # Replace placeholder in prompt template\n",
    "    prompt_template = stage_3_prompt100.replace(\"{{summary_from_stage_1}}\", stage1_result.get('Summary', ''))\n",
    "    \n",
    "    # Process each knowledge point\n",
    "    for knowledge_point_index, knowledge_point in enumerate(knowledge_points):\n",
    "        print(f\"\\nProcessing knowledge point {knowledge_point_index+1}/{len(knowledge_points)}\")\n",
    "        print(f\"Knowledge point: {knowledge_point[:100]}...\" if len(knowledge_point) > 100 else knowledge_point)\n",
    "        \n",
    "        # Collect all screenshots for this knowledge point from all attempts\n",
    "        point_screenshots = []\n",
    "        point_screenshot_ids = []\n",
    "        \n",
    "        for attempt_result in stage2_result['attempt_results']:\n",
    "            for item in attempt_result:\n",
    "                if item[\"knowledge_point_index\"] == knowledge_point_index:\n",
    "                    for screenshot_index, path in enumerate(item.get(\"screenshot_paths\", [])):\n",
    "                        # Extract base filename as ID\n",
    "                        filename = os.path.basename(path)\n",
    "                        name_without_ext = os.path.splitext(filename)[0]\n",
    "                        \n",
    "                        point_screenshots.append(path)\n",
    "                        point_screenshot_ids.append(name_without_ext)\n",
    "        \n",
    "        # If no screenshots found, skip this knowledge point\n",
    "        if not point_screenshots:\n",
    "            print(f\"No screenshots found for knowledge point {knowledge_point_index+1}\")\n",
    "            curated_results.append({\n",
    "                \"knowledge_point_index\": knowledge_point_index,\n",
    "                \"knowledge_point\": knowledge_point,\n",
    "                \"screenshots\": [],\n",
    "                \"captions\": []\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        print(f\"Found {len(point_screenshots)} screenshots for curation\")\n",
    "        \n",
    "        # Check if there's a reasonable number of screenshots to process\n",
    "        if len(point_screenshots) > 20:\n",
    "            print(f\"Warning: Large number of screenshots ({len(point_screenshots)}). Processing may take time.\")\n",
    "        \n",
    "        # Create the input for GPT-4o\n",
    "        user_content = [\n",
    "            {\"type\": \"text\", \"text\": f\"Knowledge point: {knowledge_point}\\n\\nBelow are screenshots to curate:\"}\n",
    "        ]\n",
    "        \n",
    "        # Add images to the content\n",
    "        for path, screenshot_id in zip(point_screenshots, point_screenshot_ids):\n",
    "            base64_image = image_to_base64(path)\n",
    "            if base64_image:\n",
    "                user_content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                })\n",
    "                user_content.append({\"type\": \"text\", \"text\": f\"Image ID: {screenshot_id}\"})  \n",
    "        \n",
    "        # Call GPT-4o\n",
    "        print(f\"Calling o1 API for curation...\")\n",
    "        try:\n",
    "            response = openai_client.chat.completions.create(\n",
    "                model=\"o1\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt_template},\n",
    "                    {\"role\": \"user\", \"content\": user_content}\n",
    "                ],\n",
    "                #max_tokens=4000\n",
    "                reasoning_effort=\"low\"\n",
    "            )\n",
    "            \n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # Save the raw response\n",
    "            raw_response_path = os.path.join(base_folder, f\"stage3_raw_response_point_{knowledge_point_index+1}.txt\")\n",
    "            with open(raw_response_path, 'w') as f:\n",
    "                f.write(response_text)\n",
    "            \n",
    "            # Parse the response to get curated screenshots\n",
    "            curated_data = parse_gemini_response(response_text)  # Reusing the same parsing function\n",
    "            \n",
    "            if not curated_data or not isinstance(curated_data, dict):\n",
    "                print(f\"Failed to parse GPT-4o response for point {knowledge_point_index+1}\")\n",
    "                curated_results.append({\n",
    "                    \"knowledge_point_index\": knowledge_point_index,\n",
    "                    \"knowledge_point\": knowledge_point,\n",
    "                    \"screenshot_groups\": [],\n",
    "                    \"selected_screenshots\": [],\n",
    "                    \"captions\": []\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Extract selected screenshots\n",
    "            selected_ids = curated_data.get(\"selected_indexes\", [])\n",
    "            captions = curated_data.get(\"captions\", [])\n",
    "            groups = curated_data.get(\"groups\", [])\n",
    "            \n",
    "            # Map IDs back to file paths\n",
    "            selected_paths = []\n",
    "            for selected_id in selected_ids:\n",
    "                # Find the matching screenshot path\n",
    "                found = False\n",
    "                for i, id_val in enumerate(point_screenshot_ids):\n",
    "                    if id_val == selected_id:\n",
    "                        selected_paths.append(point_screenshots[i])\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    print(f\"Warning: Selected ID {selected_id} not found in screenshots\")\n",
    "            \n",
    "            print(f\"o1 selected {len(selected_paths)} out of {len(point_screenshots)} screenshots\")\n",
    "            \n",
    "            # Add results for this knowledge point\n",
    "            curated_results.append({\n",
    "                \"knowledge_point_index\": knowledge_point_index,\n",
    "                \"knowledge_point\": knowledge_point,\n",
    "                \"screenshot_groups\": groups,\n",
    "                \"selected_screenshots\": selected_paths,\n",
    "                \"selected_ids\": selected_ids,\n",
    "                \"captions\": captions\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calling GPT-4o API: {str(e)}\")\n",
    "            # Add empty result for this knowledge point\n",
    "            curated_results.append({\n",
    "                \"knowledge_point_index\": knowledge_point_index,\n",
    "                \"knowledge_point\": knowledge_point,\n",
    "                \"screenshot_groups\": [],\n",
    "                \"selected_screenshots\": [],\n",
    "                \"captions\": []\n",
    "            })\n",
    "    \n",
    "    # Save combined results\n",
    "    stage3_result = {\n",
    "        \"curated_knowledge_points\": curated_results,\n",
    "    }\n",
    "    \n",
    "    stage3_result_path = os.path.join(base_folder, \"stage3_result.json\")\n",
    "    with open(stage3_result_path, 'w') as f:\n",
    "        json.dump(stage3_result, f, indent=2)\n",
    "    \n",
    "    # Count total selected screenshots\n",
    "    total_selected = sum(len(item.get(\"selected_screenshots\", [])) for item in curated_results)\n",
    "    print(f\"\\nStage 3 completed with {total_selected} selected screenshots across {len(curated_results)} knowledge points\")\n",
    "    return stage3_result\n",
    "\n",
    "# Run Stage 3\n",
    "stage3_result = stage3_curate_screenshots(stage1_result_json, stage2_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display a sample of the curated results\n",
    "if stage3_result and 'curated_knowledge_points' in stage3_result:\n",
    "    curated_points = stage3_result['curated_knowledge_points']\n",
    "    if curated_points:\n",
    "        # Find a point with screenshots to display\n",
    "        for point in curated_points:\n",
    "            if point.get('selected_screenshots'):\n",
    "                print(f\"\\nSample Curated Point - Knowledge Point {point['knowledge_point_index']+1}:\")\n",
    "                print(f\"Knowledge point: {point['knowledge_point'][:100]}...\" if len(point['knowledge_point']) > 100 else point['knowledge_point'])\n",
    "                print(f\"Selected {len(point['selected_screenshots'])} screenshots\")\n",
    "                \n",
    "                # Display first screenshot and caption\n",
    "                if point['selected_screenshots'] and point['captions']:\n",
    "                    sample_path = point['selected_screenshots'][0]\n",
    "                    caption = point['captions'][0] if 0 < len(point['captions']) else \"No caption\"\n",
    "                    print(f\"Caption: {caption}\")\n",
    "                    display(Image(filename=sample_path, width=400))\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Final DOCX Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating Final DOCX Document ===\n",
      "Document successfully saved: training_job_1743966405/training_document.docx\n",
      "\n",
      "Final document generated and saved to: training_job_1743966405/training_document.docx\n"
     ]
    }
   ],
   "source": [
    "# Generate final DOCX document\n",
    "\n",
    "def generate_final_document(stage1_result, stage3_result):\n",
    "    print(\"=== Generating Final DOCX Document ===\")\n",
    "    \n",
    "    # Check if we have the required data\n",
    "    if not stage1_result or 'Summary' not in stage1_result:\n",
    "        print(\"Error: Missing required data from Stage 1\")\n",
    "        return None\n",
    "    \n",
    "    if not stage3_result or 'curated_knowledge_points' not in stage3_result:\n",
    "        print(\"Error: Missing required data from Stage 3\")\n",
    "        return None\n",
    "    \n",
    "    curated_points = stage3_result['curated_knowledge_points']\n",
    "    \n",
    "    # Create document\n",
    "    document = Document()\n",
    "    \n",
    "    # Add title\n",
    "    title = document.add_heading('Training Document', 0)\n",
    "    title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    # Add Summary section\n",
    "    document.add_heading('Summary', level=1)\n",
    "    document.add_paragraph(stage1_result['Summary'])\n",
    "    document.add_paragraph('')  # Add some space\n",
    "    \n",
    "    # Add knowledge points with screenshots\n",
    "    document.add_heading('Knowledge Points', level=1)\n",
    "    \n",
    "    for point in curated_points:\n",
    "        point_index = point['knowledge_point_index']\n",
    "        knowledge_point = point['knowledge_point']\n",
    "        \n",
    "        # Add knowledge point as heading\n",
    "        document.add_heading(f\"{point_index+1}. {knowledge_point}\", level=2)\n",
    "        \n",
    "        # Add screenshots with captions\n",
    "        selected_screenshots = point.get('selected_screenshots', [])\n",
    "        captions = point.get('captions', [])\n",
    "        \n",
    "        if not selected_screenshots:\n",
    "            paragraph = document.add_paragraph(\"No relevant screenshots available for this knowledge point.\")\n",
    "            paragraph.style = 'Intense Quote'\n",
    "            continue\n",
    "            \n",
    "        # Add screenshots with captions\n",
    "        for i, (screenshot_path, caption) in enumerate(zip(selected_screenshots, captions)):\n",
    "            try:\n",
    "                # Add a separator between screenshots if not the first one\n",
    "                if i > 0:\n",
    "                    document.add_paragraph('')  # Add blank line between screenshots\n",
    "                \n",
    "                # Add the screenshot\n",
    "                document.add_picture(screenshot_path, width=Inches(6.0))\n",
    "                \n",
    "                # Add the caption below the screenshot\n",
    "                caption_paragraph = document.add_paragraph(f\"Figure {point_index+1}.{i+1}: {caption}\")\n",
    "                caption_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "                caption_paragraph.style = 'Caption'\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error adding screenshot {screenshot_path}: {str(e)}\")\n",
    "                error_paragraph = document.add_paragraph(f\"Error: Could not add screenshot {os.path.basename(screenshot_path)}\")\n",
    "                error_paragraph.style = 'Intense Quote'\n",
    "    \n",
    "    # Add a footer with timestamp\n",
    "    section = document.sections[0]\n",
    "    footer = section.footer\n",
    "    footer_paragraph = footer.paragraphs[0] if footer.paragraphs else footer.add_paragraph()\n",
    "    footer_paragraph.text = f\"Generated on {time.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "    footer_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    # Save the document\n",
    "    try:\n",
    "        document.save(output_docx_path)\n",
    "        print(f\"Document successfully saved: {output_docx_path}\")\n",
    "        return output_docx_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving document: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Run Stage 4: Generate Final Document\n",
    "if 'stage1_result_json' in locals() and 'stage3_result' in locals():\n",
    "    output_path = generate_final_document(stage1_result_json, stage3_result)\n",
    "    if output_path:\n",
    "        print(f\"\\nFinal document generated and saved to: {output_path}\")\n",
    "else:\n",
    "    print(\"Missing required data to generate final document. Please run all previous stages first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating Final DOCX Document ===\n"
     ]
    }
   ],
   "source": [
    "generate_final_document(stage1_result_json, stage3_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
