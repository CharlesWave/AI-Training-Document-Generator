{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Stage Training Document Generation\n",
    "\n",
    "This notebook implements a 3-stage process for generating training documents:\n",
    "1. Use Gemini to analyze video and extract knowledge points\n",
    "2. Use Gemini to select timestamps for screenshots (3 separate API calls)\n",
    "3. Use OpenAI GPT-4o to curate screenshots and captions\n",
    "4. Generate final DOCX document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import requests\n",
    "from google import genai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import base64\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "import re\n",
    "from IPython.display import display, Image\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables with API keys\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize API clients\n",
    "GEMINI_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "gemni_client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
    "openai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Import prompts\n",
    "from three_stage_testing.prompts_Three_Stage import stage_1_prompt100, stage_2_prompt100, stage_3_prompt100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Paths and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths and settings\n",
    "video_path = \"KT Recording/modify table in EDW using git.mp4\"  # Update this to your video path\n",
    "job_id = int(time.time())  # Generate a unique ID for this job\n",
    "\n",
    "# Create directories for outputs\n",
    "base_folder = f\"training_job_{job_id}\"\n",
    "os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "# Folders for the 3 API attempts in stage 2\n",
    "screenshots_folders = [\n",
    "    os.path.join(base_folder, f\"screenshots_attempt_{i+1}\") for i in range(3)\n",
    "]\n",
    "for folder in screenshots_folders:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# Final output paths\n",
    "output_json_path = os.path.join(base_folder, \"training_data.json\")\n",
    "output_docx_path = os.path.join(base_folder, \"training_document.docx\")\n",
    "\n",
    "print(f\"Job ID: {job_id}\")\n",
    "print(f\"Output folder: {base_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def extract_screenshots(video_path, timestamps, output_folder, knowledge_point_index, api_attempt_index):\n",
    "    \"\"\"Extract screenshots from video at given timestamps\"\"\"\n",
    "    screenshot_paths = []\n",
    "    \n",
    "    try:\n",
    "        # Open the video file\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Could not open video file {video_path}\")\n",
    "            return []\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration = total_frames / fps if fps > 0 else 0\n",
    "        \n",
    "        print(f\"Video properties: Duration={duration:.2f}s, FPS={fps:.2f}, Total frames={total_frames}\")\n",
    "        \n",
    "        # Process each timestamp\n",
    "        for screenshot_index, timestamp in enumerate(timestamps):\n",
    "            try:\n",
    "                # Parse timestamp (assuming format like \"1:30\")\n",
    "                if ':' in timestamp:\n",
    "                    minutes, seconds = timestamp.split(':')\n",
    "                    time_in_seconds = int(minutes) * 60 + float(seconds)\n",
    "                else:\n",
    "                    # If only seconds are provided\n",
    "                    time_in_seconds = float(timestamp)\n",
    "                \n",
    "                # Skip if timestamp is beyond video duration\n",
    "                if duration > 0 and time_in_seconds > duration:\n",
    "                    print(f\"Timestamp {timestamp} exceeds video duration of {duration:.2f}s\")\n",
    "                    continue\n",
    "                \n",
    "                # Set the frame position\n",
    "                cap.set(cv2.CAP_PROP_POS_MSEC, time_in_seconds * 1000)\n",
    "                \n",
    "                # Read the frame\n",
    "                success, frame = cap.read()\n",
    "                if success:\n",
    "                    # Generate filename using the specified format\n",
    "                    screenshot_filename = f\"{knowledge_point_index+1}_{screenshot_index+1}_{api_attempt_index+1}.png\"\n",
    "                    screenshot_path = os.path.join(output_folder, screenshot_filename)\n",
    "                    \n",
    "                    # Save the frame\n",
    "                    cv2.imwrite(screenshot_path, frame)\n",
    "                    screenshot_paths.append(screenshot_path)\n",
    "                    print(f\"Saved screenshot: {screenshot_path}\")\n",
    "                else:\n",
    "                    print(f\"Failed to capture screenshot at timestamp {timestamp}\")\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing timestamp {timestamp}: {str(e)}\")\n",
    "        \n",
    "        # Release the video capture\n",
    "        cap.release()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in extract_screenshots: {str(e)}\")\n",
    "    \n",
    "    return screenshot_paths\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \"\"\"Convert an image file to base64 encoded string\"\"\"\n",
    "    try:\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "            return encoded_string\n",
    "    except Exception as e:\n",
    "        print(f\"Error encoding image to base64: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def parse_gemini_response(response_text):\n",
    "    \"\"\"Parse the response from Gemini to extract JSON\"\"\"\n",
    "    try:\n",
    "        # Try to parse the entire response as JSON\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        # If that fails, look for JSON content in markdown code blocks\n",
    "        json_pattern = r'```(?:json)?\\s*([\\s\\S]*?)\\s*```'\n",
    "        matches = re.findall(json_pattern, response_text)\n",
    "        \n",
    "        if matches:\n",
    "            try:\n",
    "                return json.loads(matches[0])\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse JSON from code block: {matches[0]}\")\n",
    "                \n",
    "        # If no code blocks or parsing failed, try to find JSON-like structures\n",
    "        start_idx = response_text.find('{')\n",
    "        end_idx = response_text.rfind('}')\n",
    "        if start_idx >= 0 and end_idx > start_idx:\n",
    "            try:\n",
    "                json_str = response_text[start_idx:end_idx+1]\n",
    "                return json.loads(json_str)\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Failed to parse JSON-like structure: {json_str}\")\n",
    "                \n",
    "        print(\"Could not extract valid JSON from response\")\n",
    "        print(\"Response text:\")\n",
    "        print(response_text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1: Use Gemini to Extract Knowledge Points from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Use Gemini to extract knowledge points from video\n",
    "\n",
    "def stage1_extract_knowledge_points(video_path):\n",
    "    print(\"=== Stage 1: Extracting Knowledge Points ===\")\n",
    "    \n",
    "    # Read the video file\n",
    "    with open(video_path, 'rb') as f:\n",
    "        video_data = f.read()\n",
    "    \n",
    "    # Create a Gemini model instance (using the Vision model for video)\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-vision')\n",
    "    \n",
    "    print(f\"Sending video to Gemini for analysis...\")\n",
    "    \n",
    "    # Create the prompt with video\n",
    "    contents = [\n",
    "        stage_1_prompt100,\n",
    "        {\"mime_type\": \"video/mp4\", \"data\": video_data}\n",
    "    ]\n",
    "    \n",
    "    # Call the Gemini API\n",
    "    response = model.generate_content(contents)\n",
    "    response_text = response.text\n",
    "    \n",
    "    # Parse the response\n",
    "    print(\"Parsing response from Gemini...\")\n",
    "    result = parse_gemini_response(response_text)\n",
    "    \n",
    "    if result and isinstance(result, dict):\n",
    "        # Save the result\n",
    "        stage1_result_path = os.path.join(base_folder, \"stage1_result.json\")\n",
    "        with open(stage1_result_path, 'w') as f:\n",
    "            json.dump(result, f, indent=2)\n",
    "        \n",
    "        # Verify required fields\n",
    "        if 'Summary' in result and 'knowledge_points' in result:\n",
    "            print(f\"Successfully extracted {len(result['knowledge_points'])} knowledge points\")\n",
    "            return result\n",
    "        else:\n",
    "            print(\"Warning: Missing required fields in the result\")\n",
    "            return result\n",
    "    else:\n",
    "        print(\"Failed to parse response from Gemini\")\n",
    "        return None\n",
    "\n",
    "# Run Stage 1\n",
    "stage1_result = stage1_extract_knowledge_points(video_path)\n",
    "\n",
    "# Display summary and first few knowledge points\n",
    "if stage1_result:\n",
    "    print(\"\\nSummary:\")\n",
    "    print(stage1_result.get('Summary', 'No summary provided'))\n",
    "    \n",
    "    print(\"\\nFirst 3 Knowledge Points:\")\n",
    "    for i, point in enumerate(stage1_result.get('knowledge_points', [])[:3]):\n",
    "        print(f\"{i+1}. {point}\")\n",
    "    \n",
    "    # Display total count\n",
    "    total_points = len(stage1_result.get('knowledge_points', []))\n",
    "    if total_points > 3:\n",
    "        print(f\"...and {total_points-3} more points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2: Use Gemini to Select Timestamps (3 Attempts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Use Gemini to select timestamps for knowledge points\n",
    "\n",
    "def stage2_select_timestamps(video_path, stage1_result):\n",
    "    print(\"=== Stage 2: Selecting Timestamps for Screenshots ===\")\n",
    "    \n",
    "    # Check if we have the required data from Stage 1\n",
    "    if not stage1_result or 'knowledge_points' not in stage1_result:\n",
    "        print(\"Error: Missing required data from Stage 1\")\n",
    "        return None\n",
    "    \n",
    "    # Read the video file\n",
    "    with open(video_path, 'rb') as f:\n",
    "        video_data = f.read()\n",
    "    \n",
    "    # Create prompt with video and knowledge points\n",
    "    knowledge_points = stage1_result['knowledge_points']\n",
    "    \n",
    "    # Replace placeholder in prompt template\n",
    "    prompt = stage_2_prompt100.replace(\"{{summary_from_stage_1}}\", json.dumps(stage1_result.get('Summary', '')))\n",
    "    \n",
    "    # Create the content with prompt, video and knowledge points\n",
    "    contents = [\n",
    "        prompt,\n",
    "        {\"mime_type\": \"video/mp4\", \"data\": video_data},\n",
    "        \"Knowledge Points:\\n\" + \"\\n\".join([f\"{i+1}. {point}\" for i, point in enumerate(knowledge_points)])\n",
    "    ]\n",
    "    \n",
    "    # Create a Gemini model instance\n",
    "    model = genai.GenerativeModel('gemini-1.5-pro-vision')\n",
    "    \n",
    "    # Run 3 separate API calls and collect timestamps\n",
    "    all_attempt_results = []\n",
    "    all_screenshot_paths = []\n",
    "    \n",
    "    for attempt in range(3):\n",
    "        print(f\"\\nAttempt {attempt+1}/3: Calling Gemini API for timestamp selection...\")\n",
    "        \n",
    "        # Call the Gemini API\n",
    "        response = model.generate_content(contents)\n",
    "        response_text = response.text\n",
    "        \n",
    "        # Save the raw response\n",
    "        raw_response_path = os.path.join(base_folder, f\"stage2_raw_response_attempt_{attempt+1}.txt\")\n",
    "        with open(raw_response_path, 'w') as f:\n",
    "            f.write(response_text)\n",
    "        \n",
    "        # Parse the response to get timestamps\n",
    "        timestamps_data = parse_gemini_response(response_text)\n",
    "        \n",
    "        if not timestamps_data or not isinstance(timestamps_data, dict):\n",
    "            print(f\"Attempt {attempt+1}: Failed to parse response from Gemini\")\n",
    "            continue\n",
    "        \n",
    "        # Save parsed response\n",
    "        parsed_response_path = os.path.join(base_folder, f\"stage2_parsed_response_attempt_{attempt+1}.json\")\n",
    "        with open(parsed_response_path, 'w') as f:\n",
    "            json.dump(timestamps_data, f, indent=2)\n",
    "        \n",
    "        print(f\"Attempt {attempt+1}: Successfully parsed response\")\n",
    "        \n",
    "        # Extract timestamps for each knowledge point\n",
    "        attempt_screenshots = []\n",
    "        \n",
    "        # Extract screenshots based on timestamps\n",
    "        for knowledge_point_index, timestamps in timestamps_data.items():\n",
    "            try:\n",
    "                # Convert string index to integer if needed\n",
    "                if isinstance(knowledge_point_index, str) and knowledge_point_index.isdigit():\n",
    "                    knowledge_point_index = int(knowledge_point_index)\n",
    "                \n",
    "                if isinstance(knowledge_point_index, int) and 0 <= knowledge_point_index < len(knowledge_points):\n",
    "                    # Extract screenshots\n",
    "                    print(f\"Extracting screenshots for knowledge point {knowledge_point_index+1}\")\n",
    "                    screenshot_paths = extract_screenshots(\n",
    "                        video_path, timestamps, screenshots_folders[attempt],\n",
    "                        knowledge_point_index, attempt\n",
    "                    )\n",
    "                    \n",
    "                    attempt_screenshots.append({\n",
    "                        \"knowledge_point_index\": knowledge_point_index,\n",
    "                        \"timestamps\": timestamps,\n",
    "                        \"screenshot_paths\": screenshot_paths\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing knowledge point {knowledge_point_index}: {str(e)}\")\n",
    "        \n",
    "        all_attempt_results.append(attempt_screenshots)\n",
    "        \n",
    "        # Collect all screenshot paths\n",
    "        all_paths = []\n",
    "        for item in attempt_screenshots:\n",
    "            all_paths.extend(item[\"screenshot_paths\"])\n",
    "        all_screenshot_paths.extend(all_paths)\n",
    "        \n",
    "        print(f\"Attempt {attempt+1}: Extracted {len(all_paths)} screenshots\")\n",
    "    \n",
    "    # Save combined results\n",
    "    stage2_result = {\n",
    "        \"attempt_results\": all_attempt_results,\n",
    "        \"all_screenshot_paths\": all_screenshot_paths\n",
    "    }\n",
    "    \n",
    "    stage2_result_path = os.path.join(base_folder, \"stage2_result.json\")\n",
    "    with open(stage2_result_path, 'w') as f:\n",
    "        json.dump(stage2_result, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nStage 2 completed with {len(all_screenshot_paths)} total screenshots across 3 attempts\")\n",
    "    return stage2_result\n",
    "\n",
    "# Run Stage 2\n",
    "stage2_result = stage2_select_timestamps(video_path, stage1_result)\n",
    "\n",
    "# Display a sample of screenshots from each attempt\n",
    "if stage2_result and stage2_result['attempt_results']:\n",
    "    print(\"\\nSample screenshots from each attempt:\")\n",
    "    for i, attempt_result in enumerate(stage2_result['attempt_results']):\n",
    "        if attempt_result and len(attempt_result) > 0:\n",
    "            sample = attempt_result[0]  # Get the first knowledge point's screenshots\n",
    "            print(f\"\\nAttempt {i+1} - Knowledge Point {sample['knowledge_point_index']+1}:\")\n",
    "            print(f\"Timestamps: {sample['timestamps']}\")\n",
    "            print(f\"Screenshots: {len(sample['screenshot_paths'])} extracted\")\n",
    "            \n",
    "            # Display a sample screenshot if available\n",
    "            if sample['screenshot_paths'] and len(sample['screenshot_paths']) > 0:\n",
    "                sample_path = sample['screenshot_paths'][0]\n",
    "                display(Image(filename=sample_path, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3: Use GPT-4o to Curate Screenshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 3: Use GPT-4o to curate screenshots\n",
    "\n",
    "def stage3_curate_screenshots(stage1_result, stage2_result):\n",
    "    print(\"=== Stage 3: Curating Screenshots with GPT-4o ===\")\n",
    "    \n",
    "    # Check if we have the required data from Stages 1 and 2\n",
    "    if not stage1_result or 'knowledge_points' not in stage1_result:\n",
    "        print(\"Error: Missing required data from Stage 1\")\n",
    "        return None\n",
    "    \n",
    "    if not stage2_result or 'attempt_results' not in stage2_result:\n",
    "        print(\"Error: Missing required data from Stage 2\")\n",
    "        return None\n",
    "    \n",
    "    # Organize screenshots by knowledge point\n",
    "    knowledge_points = stage1_result['knowledge_points']\n",
    "    curated_results = []\n",
    "    \n",
    "    # Replace placeholder in prompt template\n",
    "    prompt_template = stage_3_prompt100.replace(\"{{summary_from_stage_1}}\", json.dumps(stage1_result.get('Summary', '')))\n",
    "    \n",
    "    # Process each knowledge point\n",
    "    for knowledge_point_index, knowledge_point in enumerate(knowledge_points):\n",
    "        print(f\"\\nProcessing knowledge point {knowledge_point_index+1}/{len(knowledge_points)}\")\n",
    "        print(f\"Knowledge point: {knowledge_point[:100]}...\" if len(knowledge_point) > 100 else knowledge_point)\n",
    "        \n",
    "        # Collect all screenshots for this knowledge point from all attempts\n",
    "        point_screenshots = []\n",
    "        point_screenshot_ids = []\n",
    "        \n",
    "        for attempt_index, attempt_result in enumerate(stage2_result['attempt_results']):\n",
    "            for item in attempt_result:\n",
    "                if item[\"knowledge_point_index\"] == knowledge_point_index:\n",
    "                    for screenshot_index, path in enumerate(item.get(\"screenshot_paths\", [])):\n",
    "                        # Extract base filename as ID\n",
    "                        filename = os.path.basename(path)\n",
    "                        name_without_ext = os.path.splitext(filename)[0]\n",
    "                        \n",
    "                        point_screenshots.append(path)\n",
    "                        point_screenshot_ids.append(name_without_ext)\n",
    "        \n",
    "        # If no screenshots found, skip this knowledge point\n",
    "        if not point_screenshots:\n",
    "            print(f\"No screenshots found for knowledge point {knowledge_point_index+1}\")\n",
    "            curated_results.append({\n",
    "                \"knowledge_point_index\": knowledge_point_index,\n",
    "                \"knowledge_point\": knowledge_point,\n",
    "                \"screenshots\": [],\n",
    "                \"captions\": []\n",
    "            })\n",
    "            continue\n",
    "        \n",
    "        print(f\"Found {len(point_screenshots)} screenshots for curation\")\n",
    "        \n",
    "        # Check if there's a reasonable number of screenshots to process\n",
    "        if len(point_screenshots) > 20:\n",
    "            print(f\"Warning: Large number of screenshots ({len(point_screenshots)}). Processing may take time.\")\n",
    "        \n",
    "        # Create the input for GPT-4o\n",
    "        user_content = [\n",
    "            {\"type\": \"text\", \"text\": f\"Knowledge point: {knowledge_point}\\n\\nBelow are screenshots to curate:\"}\n",
    "        ]\n",
    "        \n",
    "        # Add images to the content\n",
    "        for path, screenshot_id in zip(point_screenshots, point_screenshot_ids):\n",
    "            base64_image = image_to_base64(path)\n",
    "            if base64_image:\n",
    "                user_content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                })\n",
    "                user_content.append({\"type\": \"text\", \"text\": f\"Image ID: {screenshot_id}\"})  \n",
    "        \n",
    "        # Call GPT-4o\n",
    "        print(f\"Calling GPT-4o API for curation...\")\n",
    "        try:\n",
    "            response = openai_client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt_template},\n",
    "                    {\"role\": \"user\", \"content\": user_content}\n",
    "                ],\n",
    "                max_tokens=4000\n",
    "            )\n",
    "            \n",
    "            response_text = response.choices[0].message.content\n",
    "            \n",
    "            # Save the raw response\n",
    "            raw_response_path = os.path.join(base_folder, f\"stage3_raw_response_point_{knowledge_point_index+1}.txt\")\n",
    "            with open(raw_response_path, 'w') as f:\n",
    "                f.write(response_text)\n",
    "            \n",
    "            # Parse the response to get curated screenshots\n",
    "            curated_data = parse_gemini_response(response_text)  # Reusing the same parsing function\n",
    "            \n",
    "            if not curated_data or not isinstance(curated_data, dict):\n",
    "                print(f\"Failed to parse GPT-4o response for point {knowledge_point_index+1}\")\n",
    "                curated_results.append({\n",
    "                    \"knowledge_point_index\": knowledge_point_index,\n",
    "                    \"knowledge_point\": knowledge_point,\n",
    "                    \"screenshot_groups\": [],\n",
    "                    \"selected_screenshots\": [],\n",
    "                    \"captions\": []\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Extract selected screenshots\n",
    "            selected_ids = curated_data.get(\"selected_indexes\", [])\n",
    "            captions = curated_data.get(\"captions\", [])\n",
    "            groups = curated_data.get(\"groups\", [])\n",
    "            \n",
    "            # Map IDs back to file paths\n",
    "            selected_paths = []\n",
    "            for selected_id in selected_ids:\n",
    "                # Find the matching screenshot path\n",
    "                found = False\n",
    "                for i, id_val in enumerate(point_screenshot_ids):\n",
    "                    if id_val == selected_id:\n",
    "                        selected_paths.append(point_screenshots[i])\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    print(f\"Warning: Selected ID {selected_id} not found in screenshots\")\n",
    "            \n",
    "            print(f\"GPT-4o selected {len(selected_paths)} out of {len(point_screenshots)} screenshots\")\n",
    "            \n",
    "            # Add results for this knowledge point\n",
    "            curated_results.append({\n",
    "                \"knowledge_point_index\": knowledge_point_index,\n",
    "                \"knowledge_point\": knowledge_point,\n",
    "                \"screenshot_groups\": groups,\n",
    "                \"selected_screenshots\": selected_paths,\n",
    "                \"selected_ids\": selected_ids,\n",
    "                \"captions\": captions\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error calling GPT-4o API: {str(e)}\")\n",
    "            # Add empty result for this knowledge point\n",
    "            curated_results.append({\n",
    "                \"knowledge_point_index\": knowledge_point_index,\n",
    "                \"knowledge_point\": knowledge_point,\n",
    "                \"screenshot_groups\": [],\n",
    "                \"selected_screenshots\": [],\n",
    "                \"captions\": []\n",
    "            })\n",
    "    \n",
    "    # Save combined results\n",
    "    stage3_result = {\n",
    "        \"curated_knowledge_points\": curated_results,\n",
    "    }\n",
    "    \n",
    "    stage3_result_path = os.path.join(base_folder, \"stage3_result.json\")\n",
    "    with open(stage3_result_path, 'w') as f:\n",
    "        json.dump(stage3_result, f, indent=2)\n",
    "    \n",
    "    # Count total selected screenshots\n",
    "    total_selected = sum(len(item.get(\"selected_screenshots\", [])) for item in curated_results)\n",
    "    print(f\"\\nStage 3 completed with {total_selected} selected screenshots across {len(curated_results)} knowledge points\")\n",
    "    return stage3_result\n",
    "\n",
    "# Run Stage 3\n",
    "stage3_result = stage3_curate_screenshots(stage1_result, stage2_result)\n",
    "\n",
    "# Display a sample of the curated results\n",
    "if stage3_result and 'curated_knowledge_points' in stage3_result:\n",
    "    curated_points = stage3_result['curated_knowledge_points']\n",
    "    if curated_points:\n",
    "        # Find a point with screenshots to display\n",
    "        for point in curated_points:\n",
    "            if point.get('selected_screenshots'):\n",
    "                print(f\"\\nSample Curated Point - Knowledge Point {point['knowledge_point_index']+1}:\")\n",
    "                print(f\"Knowledge point: {point['knowledge_point'][:100]}...\" if len(point['knowledge_point']) > 100 else point['knowledge_point'])\n",
    "                print(f\"Selected {len(point['selected_screenshots'])} screenshots\")\n",
    "                \n",
    "                # Display first screenshot and caption\n",
    "                if point['selected_screenshots'] and point['captions']:\n",
    "                    sample_path = point['selected_screenshots'][0]\n",
    "                    caption = point['captions'][0] if 0 < len(point['captions']) else \"No caption\"\n",
    "                    print(f\"Caption: {caption}\")\n",
    "                    display(Image(filename=sample_path, width=400))\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Final DOCX Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final DOCX document\n",
    "\n",
    "def generate_final_document(stage1_result, stage3_result):\n",
    "    print(\"=== Generating Final DOCX Document ===\")\n",
    "    \n",
    "    # Check if we have the required data\n",
    "    if not stage1_result or 'Summary' not in stage1_result:\n",
    "        print(\"Error: Missing required data from Stage 1\")\n",
    "        return None\n",
    "    \n",
    "    if not stage3_result or 'curated_knowledge_points' not in stage3_result:\n",
    "        print(\"Error: Missing required data from Stage 3\")\n",
    "        return None\n",
    "    \n",
    "    curated_points = stage3_result['curated_knowledge_points']\n",
    "    \n",
    "    # Create document\n",
    "    document = Document()\n",
    "    \n",
    "    # Add title\n",
    "    title = document.add_heading('Training Document', 0)\n",
    "    title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    \n",
    "    # Add Summary section\n",
    "    document.add_heading('Summary', level=1)\n",
    "    document.add_paragraph(stage1_result['Summary'])\n",
    "    document.add_paragraph('')  # Add some space\n",
    "    \n",
    "    # Add knowledge points with screenshots\n",
    "    document.add_heading('Knowledge Points', level=1)\n",
    "    \n",
    "    for point in curated_points:\n",
    "        point_index = point['knowledge_point_index']\n",
    "        knowledge_point = point['knowledge_point']\n",
    "        \n",
    "        # Add knowledge point as heading\n",
    "        document.add_heading(f\"{point_index+1}. {knowledge_point}\", level=2)\n",
    "        \n",
    "        # Add screenshots with captions\n",
    "        selected_screenshots = point.get('selected_screenshots', [])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
